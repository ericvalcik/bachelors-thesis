%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% I, the copyright holder of this work, release this work into the
%% public domain. This applies worldwide. In some countries this may
%% not be legally possible; if so: I grant anyone the right to use
%% this work for any purpose, without any conditions, unless such
%% conditions are required by law.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[
  digital,     %% The `digital` option enables the default options for the
               %% digital version of a document. Replace with `printed`
               %% to enable the default options for the printed version
               %% of a document.
%%  color,       %% Uncomment these lines (by removing the %% at the
%%               %% beginning) to use color in the printed version of your
%%               %% document
  oneside,     %% The `oneside` option enables one-sided typesetting,
               %% which is preferred if you are only going to submit a
               %% digital version of your thesis. Replace with `twoside`
               %% for double-sided typesetting if you are planning to
               %% also print your thesis. For double-sided typesetting,
               %% use at least 120 g/m² paper to prevent show-through.
  nosansbold,  %% The `nosansbold` option prevents the use of the
               %% sans-serif type face for bold text. Replace with
               %% `sansbold` to use sans-serif type face for bold text.
  nocolorbold, %% The `nocolorbold` option disables the usage of the
               %% blue color for bold text, instead using black. Replace
               %% with `colorbold` to use blue for bold text.
  nolof,         %% The `lof` option prints the List of Figures. Replace
               %% with `nolof` to hide the List of Figures.
  nolot,         %% The `lot` option prints the List of Tables. Replace
               %% with `nolot` to hide the List of Tables.
]{fithesis4}
%% The following section sets up the locales used in the thesis.
\usepackage[resetfonts]{cmap} %% We need to load the T2A font encoding
\usepackage[T1,T2A]{fontenc}  %% to use the Cyrillic fonts with Russian texts.
\usepackage[
  main=english, %% By using `czech` or `slovak` as the main locale
                %% instead of `english`, you can typeset the thesis
                %% in either Czech or Slovak, respectively.
  english, german, russian, czech, slovak %% The additional keys allow
]{babel}        %% foreign texts to be typeset as follows:
%%
%%   \begin{otherlanguage}{german}  ... \end{otherlanguage}
%%   \begin{otherlanguage}{russian} ... \end{otherlanguage}
%%   \begin{otherlanguage}{czech}   ... \end{otherlanguage}
%%   \begin{otherlanguage}{slovak}  ... \end{otherlanguage}
%%
%% For non-Latin scripts, it may be necessary to load additional
%% fonts:
\usepackage{paratype}
\def\textrussian#1{{\usefont{T2A}{PTSerif-TLF}{m}{rm}#1}}
%%
%% The following section sets up the metadata of the thesis.
\thesissetup{
    date        = \the\year/\the\month/\the\day,
    university  = mu,
    faculty     = fi,
    type        = bc,
    department  = Department of Machine Learning and Data Processing,
    author      = Eric Vincent Valčík,
    gender      = m,
    advisor     = {doc. Mgr. Radek Pelánek, Ph.D.},
    title       = {Detection of Czech Words in pictures},
    TeXtitle    = {Detection of Czech Words in pictures},
    keywords    = {keyword1, keyword2, ...},
    TeXkeywords = {keyword1, keyword2, \ldots},
    abstract    = {%
      This is the abstract of my thesis, which can

      span multiple paragraphs.
    },
    thanks      = {%
      These are the acknowledgements for my thesis, which can

      span multiple paragraphs.
    },
    bib         = bibliography.bib,
    %% Remove the following line to use the JVS 2018 faculty logo.
    facultyLogo = fithesis-fi,
}
\usepackage{makeidx}      %% The `makeidx` package contains
\makeindex                %% helper commands for index typesetting.
\usepackage[acronym]{glossaries}          %% The `glossaries` package
\renewcommand*\glspostdescription{\hfill} %% contains helper commands
\loadglsentries{example-terms-abbrs.tex}  %% for typesetting glossaries
\makenoidxglossaries                      %% and lists of abbreviations.
%% These additional packages are used within the document:
\usepackage{paralist} %% Compact list environments
\usepackage{amsmath}  %% Mathematics
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{url}      %% Hyperlinks
\usepackage{markdown} %% Lightweight markup
\usepackage{listings} %% Source code highlighting
\lstset{
  basicstyle      = \ttfamily,
  identifierstyle = \color{black},
  keywordstyle    = \color{blue},
  keywordstyle    = {[2]\color{cyan}},
  keywordstyle    = {[3]\color{olive}},
  stringstyle     = \color{teal},
  commentstyle    = \itshape\color{magenta},
  breaklines      = true,
}
\usepackage{floatrow} %% Putting captions above tables
\floatsetup[table]{capposition=top}
\usepackage[babel]{csquotes} %% Context-sensitive quotation marks
\begin{document}
%% Uncomment the following lines (by removing the %% at the beginning)
%% and to print out List of Abbreviations and/or Glossary in your
%% document. Titles for these tables can be changed by replacing the
%% titles `Abbreviations` and `Glossary`, respectively.
%% \clearpage
%% \printnoidxglossary[title={Abbreviations}, type=\acronymtype]
%% \printnoidxglossary[title={Glossary}]

\chapter{State of the art}

In this chapter, we explore the existing relevant work on OCR models and detection of text inside images. We will focus on the most advanced models and use cases. We will not be looking so deeply into research papers around OCR as the goal of this thesis was not to develop better OCR tool than the ones we can use, but to find and implement a solution with the existing OCR tools we have.

Very useful projects for navigating current OCR engines were Wikipedia\cite{ocrwikipedia} and AwesomeOCR\cite{awesomeocr}. In both projects, we have a table of the most popular OCR engines along with their license, portability to operating systems, programming language they're written in, and also languages they support.

As I'm writing this, the last update made to the AwsomeOCR project was on Nov 2021, which means that it could be abandoned. Nonetheless, this project helped me find the best OCR for this thesis so I decided to include it.

\section{Google's Could vision API \cite{googleapi}}

Google has its own proprietary tools for OCR. They provide an easy way of detecting text inside images, pdfs, and they also claim to detect handwritten text.

A benefit of using this tool is that the user will get state of the art OCR and he doesn't have to get \emph{his hands dirty}, meaning he doesn't have to understand and set up the models doing the OCR. The con of using such a service is that we have to pay Google, usually per image or per page when OCR-ing pdfs.

Similar tools provide numberous big cloud providers, like Microsoft with Azure\cite{azurevision} or Amazon with AWS\cite{awstextract}. I did not include proprietary tools like this one in my work, I only focused on free and opensource solutions.

\section{Tesseract OCR\cite{tesseract}}

Tesseract is an open-source OCR project that dates back all the way to the 90s of the 20th century. It was a proprietary software owned and developed by Hewlett-Packard Laboratories but open-sourced in 2005.

Tesseract 4 uses LSTM neural networks and works by detecting lines of text, while the previous version, Tesseract 3, was detecting groups of characters. Both of these approaches can be used when using this tool. This tool is written in C++ and has almost no external dependencies, except for an IO (input-output) library.

Tesseract OCR only provides the OCR engine as a C++ library and a CLI (command line interface), but there are third part GUIs available and also linked on the tesseract GitHub repository page.

Setting up tesseract can be more problematic than using a cloud-based solution, but now you can see the code that is processing your images and change/improve it as well.

\section{EasyOCR\cite{easyocr}}

EasyOCR is an open-source OCR tool using the \emph{PyTorch}\cite{pytorch} AI library. EasyOCR aims to be a framework with interchangeable parts for other OCR implementations, but it has its own OCR engine built in it as well. You can use EasyOCR out of the box with python or you can implement your own/change the OCR engine and then EasyOCR will only provide a framework for that engine to be run in.

EasyOCR is written in python and can be used online without downloading for example on HuggingFace \href{https://huggingface.co/spaces/tomofi/EasyOCR}{here}.

\section{Benchmarking different OCR solutions}

We named some OCR engines but don't have any tools for measuring their performance. There are articles and research papers that focus on this, benchmarking these OCR engines and then measuring their accuracy\cite{benchmark}.

In the cited article the OCR engines that are being compared are AWS Textract\cite{awstextract}, Google Cloud Vision API\cite{googleapi}, ABBYY FineReader 15, Microsoft Azure Computer Vision API\cite{azurevision} and Tesseract OCR Engine\cite{tesseract}. We already saw 4 of these in the previous sections, the only one I didn't mention yet is the ABBY FineReader.

We can see that AWS Textract performed the best with Google Cloud Vision being just as good or just behind. AWS managed to get +98\% accuracy with normal text and also handwritten text, while for example, Azure's solution has under 20\% accuracy for the handwritten category. If we take away the handwritten texts, all OCRs performed quite well, with only a small amount of differences.

We can see that the only open-sourced project in the comparison, Tesseract, didn't perform as well as the best proprietary solutions. Only Azure's OCR performed worse than Tesseract in some categories.

\end{document}
